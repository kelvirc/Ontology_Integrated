{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbE42GxgmcTO",
        "outputId": "3a1bc2b8-bc37-4b73-a6ec-fcfc5fc99a2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import *\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking if the setup to use GPU instead of cpu is ready.\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.current_device())\n",
        "print(torch.cuda.device_count())\n",
        "print(torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49-b_5gOm2W6",
        "outputId": "35b7baca-89ce-4d1e-d3ec-ccf2a07f94f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3.1+cu121\n",
            "True\n",
            "0\n",
            "1\n",
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA**"
      ],
      "metadata": {
        "id": "ebMWXt1OnG9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the pre-filtered ontology for level_3  research method and data analysis method.\n",
        "ontology_df = pd.read_csv('ontology.csv')\n",
        "\n",
        "#loading the pre-filtered synonyms for level_3  research method and data analysis method.\n",
        "\n",
        "synonyms_df = pd.read_csv('synonyms.csv')"
      ],
      "metadata": {
        "id": "FMe4T3-QnE1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check general info of the ontology\n",
        "ontology_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0OlCHX9o6_g",
        "outputId": "1948dff4-8429-45f4-bd0a-ffb7e959c20a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 899 entries, 0 to 898\n",
            "Data columns (total 16 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   ent_id      899 non-null    object \n",
            " 1   definition  899 non-null    object \n",
            " 2   label       898 non-null    object \n",
            " 3   parent      899 non-null    object \n",
            " 4   level       899 non-null    float64\n",
            " 5   related     166 non-null    object \n",
            " 6   level_1     899 non-null    object \n",
            " 7   level_2     899 non-null    object \n",
            " 8   level_3     899 non-null    object \n",
            " 9   level_4     897 non-null    object \n",
            " 10  level_5     893 non-null    object \n",
            " 11  level_6     845 non-null    object \n",
            " 12  level_7     661 non-null    object \n",
            " 13  level_8     462 non-null    object \n",
            " 14  level_9     217 non-null    object \n",
            " 15  level_10    77 non-null     object \n",
            "dtypes: float64(1), object(15)\n",
            "memory usage: 112.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ontology_df[\"ent_id\"].nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROV6X0EWpDP8",
        "outputId": "098c6bc0-f344-464a-e090-6d4619ab0135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "899"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ontology_df[\"parent\"].nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRH_jBU9pJUf",
        "outputId": "76dea6ae-881f-4f07-a340-a7017b430786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "220"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check general info of the synonyms\n",
        "synonyms_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBnKFMjMnLqs",
        "outputId": "e842f56d-f19e-4609-b9eb-0701b037fb6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 31806 entries, 0 to 31805\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   synonym  31806 non-null  object\n",
            " 1   ent_id   31806 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 497.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "synonyms_df[\"synonym\"].nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ap_hJZxPnPSZ",
        "outputId": "d7c15819-6772-4781-9060-8629c5ed9f34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31770"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "synonyms_df[\"ent_id\"].nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "736Pa2DTnQQl",
        "outputId": "8f72d1e4-ed64-4311-dc92-af16e310708e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "491"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print('Before ', synonyms_df.shape)\n",
        "#synonyms_df.drop_duplicates(inplace=True)\n",
        "#print('After: ', synonyms_df.shape)\n",
        "#resetting index to avoid issues\n",
        "#synonyms_df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "Eme_0fDknWUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_synonyms = synonyms_df.copy() # Create a copy of the original dataframe"
      ],
      "metadata": {
        "id": "OEe2GqtionVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_ontology = ontology_df.copy() # Create a copy of the original dataframe"
      ],
      "metadata": {
        "id": "w_oUVqNjpchR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_ontology = data_ontology[['parent','ent_id']]"
      ],
      "metadata": {
        "id": "qHVbt1EQpnmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_ontology['text'] = data_ontology['ent_id']"
      ],
      "metadata": {
        "id": "tyGY5r2jqcxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_synonyms['text'] = data_synonyms['synonym']"
      ],
      "metadata": {
        "id": "XyHF2xg4qfqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Converting the text in the dataframes to list.**"
      ],
      "metadata": {
        "id": "sgPm03GYqE3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_synonyms = data_synonyms[\"text\"].to_list()\n",
        "data_ontology = data_ontology[\"text\"].to_list()"
      ],
      "metadata": {
        "id": "ScRgjuTMqGjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SciBERT  Approach**"
      ],
      "metadata": {
        "id": "vmBKumJ0qu9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'data_clean' is a list of lists where each inner list contains multiple text elements\n",
        "#Since it is not a list I can just access the content of the row in the datafrme\n",
        "data_synonym_bert =  [['[CLS] ' + ' '+ synonyms_df['synonym'].iloc[index] + ' [SEP]'] for index, inner_list in synonyms_df.iterrows()]\n",
        "data_ontology_bert =  [['[CLS] ' + ' '+ ontology_df['ent_id'].iloc[index] + ' [SEP]'] for index, inner_list in ontology_df.iterrows()]"
      ],
      "metadata": {
        "id": "59Y4kPznqEit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine the first list entry\n",
        "print(data_synonym_bert[0])\n",
        "print(data_ontology_bert[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7j9VTPu9rHhZ",
        "outputId": "3ac2e9b8-f30f-4285-c927-c29129b99ddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]  QDA Miner Lite system [SEP]']\n",
            "['[CLS]  research method [SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply BERT-tokenization\n",
        "scibert_tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-Jrn423qrJui",
        "outputId": "d5c739d1-b418-4111-f5e7-3161548b765e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.42.4\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/vocab.txt\n",
            "loading file tokenizer.json from cache at None\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at None\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.42.4\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.42.4\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the pre-trained  model\n",
        "model_scibert = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AmVVZwtCrSgP",
        "outputId": "554842db-50b8-4558-c5df-73f8676981e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.42.4\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/pytorch_model.bin\n",
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of BertModel were initialized from the model checkpoint at allenai/scibert_scivocab_uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize each text\n",
        "tokenized_synonym_bert = [scibert_tokenizer.tokenize(text[0]) for text in data_synonym_bert]\n",
        "tokenized_ontology_bert = [scibert_tokenizer.tokenize(text[0]) for text in data_ontology_bert]\n",
        "\n"
      ],
      "metadata": {
        "id": "UPinGzkJrbYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine the first list entry\n",
        "print(tokenized_synonym_bert[0])\n",
        "print(tokenized_ontology_bert[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--g2_dOWrhcp",
        "outputId": "cf803ff6-5913-4fb3-fb9a-6fea01f3d7bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', 'qd', '##a', 'miner', 'lit', '##e', 'system', '[SEP]']\n",
            "['[CLS]', 'research', 'method', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the lengths of tokenized texts\n",
        "text_lengths_synonym_bert = [len(tokens) for tokens in tokenized_synonym_bert]\n",
        "text_lengths_ontology_bert = [len(tokens) for tokens in tokenized_ontology_bert]\n",
        "#determine maximum overall length\n",
        "text_lengths_bert = text_lengths_ontology_bert + text_lengths_synonym_bert\n",
        "\n",
        "\n",
        "# Determine the 85th percentile for the maximum sequence length\n",
        "max_seq_length_synonym_bert = int(np.percentile(text_lengths_synonym_bert, 85))\n",
        "print(\"Maximum sequence length synonyms:\", max_seq_length_synonym_bert)\n",
        "\n",
        "# Determine the 85th percentile for the maximum sequence length\n",
        "max_seq_length_ontology_bert = int(np.percentile(text_lengths_ontology_bert, 85))\n",
        "print(\"Maximum sequence length Ontology:\", max_seq_length_ontology_bert)\n",
        "\n",
        "# Determine the 85th percentile for the maximum sequence length\n",
        "max_seq_length_bert= int(np.percentile(text_lengths_bert, 85))\n",
        "print(\"Maximum sequence length overall:\", max_seq_length_bert)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmaC9ZcTrnMv",
        "outputId": "005b8780-19fe-4e6a-9280-a404477f60da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum sequence length synonyms: 8\n",
            "Maximum sequence length Ontology: 7\n",
            "Maximum sequence length overall: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move the model to the GPU\n",
        "model_scibert.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IhVgjm2EvoNg",
        "outputId": "8e51f8dd-5405-47d8-81d4-93146069b0f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(31090, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSdpaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.embeddings_utils import get_embeddings\n",
        "\n",
        "embeddings_ontology_scibert = get_embeddings(terms=ontology_df['ent_id'],\n",
        "                                             model_type = 'bert',\n",
        "                                             model=model_scibert,\n",
        "                                             tokenizer=scibert_tokenizer,max_seq_length =max_seq_length_bert)\n"
      ],
      "metadata": {
        "id": "yllDkTuGtzoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_synonyms_scibert = get_embeddings(terms=synonyms_df['synonym'],\n",
        "                                             model_type = 'bert',\n",
        "                                             model=model_scibert,\n",
        "                                             tokenizer=scibert_tokenizer,max_seq_length =max_seq_length_bert)"
      ],
      "metadata": {
        "id": "tovQbRnCwm5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.model_utils import save_embeddings_to_pickle\n",
        "\n",
        "save_embeddings_to_pickle(embeddings_ontology_scibert, 'embeddings_ontology_scibert.pkl')\n"
      ],
      "metadata": {
        "id": "MbTiNIH8xXeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_embeddings_to_pickle(embeddings_synonyms_scibert, 'embeddings_synonyms_scibert.pkl')"
      ],
      "metadata": {
        "id": "7Fphj4OwzMeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qgi98vVKxww1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fasttext** Aproach"
      ],
      "metadata": {
        "id": "_fl1vo_ox6iV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "def download_and_extract_fasttext(url, download_path, extract_path):\n",
        "    \"\"\"\n",
        "    Downloads and extracts a zip file from a given URL.\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL of the zip file to download.\n",
        "        download_path (str): The path where the zip file will be saved.\n",
        "        extract_path (str): The directory where the contents will be extracted.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Download the file\n",
        "    response = requests.get(url)\n",
        "    with open(download_path, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "\n",
        "    # Extract the file\n",
        "    with zipfile.ZipFile(download_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "\n",
        "    # Remove the zip file after extraction\n",
        "    os.remove(download_path)\n",
        "\n",
        "# URL of the FastText model\n",
        "url = 'https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M-subword.vec.zip'\n",
        "\n",
        "# Paths\n",
        "download_path = 'wiki-news-300d-1M-subword.vec.zip'\n",
        "extract_path = 'fasttext_vectors'\n",
        "\n",
        "# Create the extract_path directory if it doesn't exist\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# Download and extract the FastText model\n",
        "download_and_extract_fasttext(url, download_path, extract_path)\n",
        "\n",
        "print(f\"FastText model downloaded and extracted to '{extract_path}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTL7mid8z7XR",
        "outputId": "2c3e3f72-0d44-412a-9c0b-9e66495bdbb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastText model downloaded and extracted to 'fasttext_vectors'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "import re\n",
        "from utils.embeddings_utils import get_embeddings"
      ],
      "metadata": {
        "id": "bOWTcR800V7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained FastText vectors\n",
        "fasttext_model = KeyedVectors.load_word2vec_format('wiki-news-300d-1M-subword.vec')"
      ],
      "metadata": {
        "id": "0qnw6vT60ZVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_ontology_fasttext = get_embeddings(terms=ontology_df['ent_id'],\n",
        "                                             model_type = 'fasttext',\n",
        "                                             model=fasttext_model)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fgXRvp3p0iRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_synonyms_fasttextc = get_embeddings(terms=synonyms_df['synonym'],\n",
        "                                             model_type = 'fasttext',\n",
        "                                             model=fasttext_model)"
      ],
      "metadata": {
        "id": "wRYCkGp50ouC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_embeddings_to_pickle(embeddings_ontology_fasttext, 'embeddings_ontology_fasttext.pkl')"
      ],
      "metadata": {
        "id": "QImHi3F7-EjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_embeddings_to_pickle(embeddings_synonyms_fasttext, 'embeddings_synonyms_fasttext.pkl')"
      ],
      "metadata": {
        "id": "pgyNMLBf-ELE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sheilla** Aproach (Word2vec?)"
      ],
      "metadata": {
        "id": "Pg7jH_-9-fhT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_synonyms_list = data_synonyms.copy()\n",
        "data_ontology_list = data_ontology.copy()"
      ],
      "metadata": {
        "id": "kuxFEvYY-nTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine both lists to create a corpus\n",
        "combined_data = data_synonyms_list + data_ontology_list\n",
        "\n",
        "# Tokenize the text (simple whitespace tokenization)\n",
        "tokenized_data = [text.split() for text in combined_data]"
      ],
      "metadata": {
        "id": "tIM_tXGy-r_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "k7lkkv9K-ux8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Word2Vec model\n",
        "model_word2vec = Word2Vec(tokenized_data, vector_size=100, window=5, min_count=1, workers=4)"
      ],
      "metadata": {
        "id": "9tq-REPA-xfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get vectors for each word in data_synonyms_list and data_ontology_list\n",
        "embeddings_synonyms_word2vec = {word: model_word2vec.wv[word] for text in data_synonyms_list for word in text.split()}\n",
        "embeddings_ontology_word2vec = {word: model_word2vec.wv[word] for text in data_ontology_list for word in text.split()}"
      ],
      "metadata": {
        "id": "FaPYRch1-6Em"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_ontology_word2vec = get_embeddings(terms=ontology_df['ent_id'],\n",
        "                                             model_type = 'word2vec',\n",
        "                                             model=model_word2vec)"
      ],
      "metadata": {
        "id": "Ye-JH8gw_i24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_synonyms_word2vec = get_embeddings(terms=synonyms_df['synonym'],\n",
        "                                             model_type = 'word2vec',\n",
        "                                             model=model_word2vec)"
      ],
      "metadata": {
        "id": "o73r5NH6_049"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_embeddings_to_pickle(embeddings_ontology_word2vec, 'embeddings_ontology_word2vec.pkl')"
      ],
      "metadata": {
        "id": "-syv-knH_MOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_embeddings_to_pickle(embeddings_synonyms_word2vec, 'embeddings_synonyms_word2vec.pkl')"
      ],
      "metadata": {
        "id": "7RbXpx3C_MCk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}